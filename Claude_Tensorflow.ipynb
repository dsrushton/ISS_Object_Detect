{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('imagenet_classes.txt', <http.client.HTTPMessage at 0x211c3042fe0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "urllib.request.urlretrieve(url, \"imagenet_classes.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude Pretrained Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results written to video_analysis_results.txt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Set up the model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Set up the image transformer\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the class labels\n",
    "with open('imagenet_classes.txt', 'r') as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "def predict(frame):\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "    _, predicted = outputs.max(1)\n",
    "    return categories[predicted.item()]\n",
    "\n",
    "# Path to your video files\n",
    "video_path = r\"C:\\Users\\dsrus\\Desktop\\Workspace\\UAP_Python_2\\sample_1\"\n",
    "video_files = glob.glob(os.path.join(video_path, \"ISS_Download_*.mp4\"))\n",
    "\n",
    "# Analyze videos and write results\n",
    "with open(\"video_analysis_results.txt\", \"w\") as result_file:\n",
    "    for video_file in video_files:\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_count = 0\n",
    "        \n",
    "        result_file.write(f\"Analysis for {os.path.basename(video_file)}:\\n\")\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_count % fps == 0:  # Analyze one frame per second\n",
    "                prediction = predict(frame)\n",
    "                result_file.write(f\"Frame {frame_count//fps}: {prediction}\\n\")\n",
    "            \n",
    "            frame_count += 1\n",
    "        \n",
    "        cap.release()\n",
    "        result_file.write(\"\\n\")\n",
    "\n",
    "print(\"Analysis complete. Results written to video_analysis_results.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Livefeed direct ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsrus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dsrus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jPTD2gnZFUw\n",
      "[youtube] jPTD2gnZFUw: Downloading webpage\n",
      "[youtube] jPTD2gnZFUw: Downloading ios player API JSON\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "Analysis complete. Results written to iss_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import yt_dlp\n",
    "import time\n",
    "\n",
    "# Set up the model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Set up the image transformer\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the class labels\n",
    "with open('imagenet_classes.txt', 'r') as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "def predict(frame):\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "    _, predicted = outputs.max(1)\n",
    "    return categories[predicted.item()]\n",
    "\n",
    "# YouTube video URL\n",
    "url = \"https://www.youtube.com/watch?v=jPTD2gnZFUw\"\n",
    "\n",
    "# Use yt-dlp to get the stream URL\n",
    "ydl_opts = {'format': 'best'}\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info(url, download=False)\n",
    "    stream_url = info['url']\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "last_prediction_time = time.time()\n",
    "prediction = \"Initializing...\"\n",
    "\n",
    "# Open a file to write predictions\n",
    "with open(\"iss_predictions.txt\", \"w\") as f:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Make a prediction every 5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - last_prediction_time > 5:\n",
    "            prediction = predict(frame)\n",
    "            last_prediction_time = current_time\n",
    "            f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}: {prediction}\\n\")\n",
    "            f.flush()  # Ensure the prediction is written to the file immediately\n",
    "\n",
    "        # Add prediction text to the frame\n",
    "        cv2.putText(frame, f\"Prediction: {prediction}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('ISS Live Feed with Computer Vision', frame)\n",
    "\n",
    "        # Press 'ESC' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # 27 is the ASCII code for ESC\n",
    "            break\n",
    "\n",
    "    # Write final message to the file\n",
    "    f.write(\"Analysis completed.\\n\")\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Analysis complete. Results written to iss_predictions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsrus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dsrus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jPTD2gnZFUw\n",
      "[youtube] jPTD2gnZFUw: Downloading webpage\n",
      "[youtube] jPTD2gnZFUw: Downloading ios player API JSON\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "Analysis complete. Results written to iss_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import yt_dlp\n",
    "import time\n",
    "\n",
    "# Set up the model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Set up the image transformer\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the class labels\n",
    "with open('imagenet_classes.txt', 'r') as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "def predict(frame):\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "    _, predicted = outputs.max(1)\n",
    "    return categories[predicted.item()]\n",
    "\n",
    "# YouTube video URL\n",
    "url = \"https://www.youtube.com/watch?v=jPTD2gnZFUw\"\n",
    "\n",
    "# Use yt-dlp to get the stream URL\n",
    "ydl_opts = {'format': 'best'}\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info(url, download=False)\n",
    "    stream_url = info['url']\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "last_prediction_time = time.time()\n",
    "prediction = \"Initializing...\"\n",
    "\n",
    "# Open a file to write predictions\n",
    "with open(\"iss_predictions.txt\", \"w\") as f:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Make a prediction every 5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - last_prediction_time > 5:\n",
    "            prediction = predict(frame)\n",
    "            last_prediction_time = current_time\n",
    "            f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}: {prediction}\\n\")\n",
    "            f.flush()  # Ensure the prediction is written to the file immediately\n",
    "\n",
    "        # Add prediction text to the frame\n",
    "        cv2.putText(frame, f\"Prediction: {prediction}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('ISS Live Feed with Computer Vision', frame)\n",
    "\n",
    "        # Press 'ESC' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # 27 is the ASCII code for ESC\n",
    "            break\n",
    "\n",
    "    # Write final message to the file\n",
    "    f.write(\"Analysis completed.\\n\")\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Analysis complete. Results written to iss_predictions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude Rewrote for Tensorflow, with model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - accuracy: 0.1463 - loss: nan\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: nan\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jPTD2gnZFUw\n",
      "[youtube] jPTD2gnZFUw: Downloading webpage\n",
      "[youtube] jPTD2gnZFUw: Downloading ios player API JSON\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "Analysis complete. Results written to iss_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yt_dlp\n",
    "import time\n",
    "\n",
    "# Define the classes\n",
    "class_names = ['space', 'earth_broad', 'iss', 'panels']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# 1. Load and preprocess data from train.record\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "    feature_description = {\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/class/label': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_features['image/encoded'], channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    label = parsed_features['image/object/class/label']\n",
    "    # Convert label to one-hot encoding\n",
    "    label = tf.reduce_max(tf.one_hot(label - 1, depth=num_classes), axis=0)  # Subtract 1 if your labels start from 1\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(record_file, batch_size):\n",
    "    dataset = tf.data.TFRecordDataset(record_file)\n",
    "    dataset = dataset.map(parse_tfrecord)\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Load your dataset\n",
    "train_dataset = load_dataset('C:/Users/dsrus/Desktop/Workspace/UAP_Python_2/train.record', batch_size=32)\n",
    "\n",
    "# 2. Set up the ResNet50 model for fine-tuning\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. Train the model\n",
    "\n",
    "history = model.fit(train_dataset, epochs=10)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save('C:/Users/dsrus/Desktop/Workspace/UAP_Python_2/fine_tuned_resnet50_tf.keras')\n",
    "\n",
    "# 4. Use the fine-tuned model to analyze the ISS live feed\n",
    "\n",
    "def predict(frame):\n",
    "    # Preprocess the frame\n",
    "    image = cv2.resize(frame, (224, 224))\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(image)\n",
    "    top_indices = predictions[0].argsort()[-4:][::-1]  # Get all 4 classes, sorted by probability\n",
    "    top_predictions = [(class_names[i], predictions[0][i]) for i in top_indices]\n",
    "    \n",
    "    return top_predictions\n",
    "\n",
    "# YouTube video URL\n",
    "url = \"https://www.youtube.com/watch?v=jPTD2gnZFUw\"\n",
    "\n",
    "# Use yt-dlp to get the stream URL\n",
    "ydl_opts = {'format': 'best'}\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info(url, download=False)\n",
    "    stream_url = info['url']\n",
    "\n",
    "# ... (previous code remains the same)\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "last_prediction_time = time.time()\n",
    "predictions = []  # Initialize as an empty list\n",
    "\n",
    "# Open a file to write predictions\n",
    "with open(\"iss_predictions.txt\", \"w\") as f:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize frame for display\n",
    "        display_frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "        # Make a prediction every 5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - last_prediction_time > 5:\n",
    "            predictions = predict(frame)\n",
    "            last_prediction_time = current_time\n",
    "            f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}: {', '.join([f'{p[0]} ({p[1]:.2f})' for p in predictions])}\\n\")\n",
    "            f.flush()  # Ensure the prediction is written to the file immediately\n",
    "\n",
    "        # Add predictions text to the frame\n",
    "        if predictions:\n",
    "            for i, (pred, prob) in enumerate(predictions):  # Display all 4 classes\n",
    "                cv2.putText(display_frame, f\"{i+1}. {pred} ({prob:.2f})\", (10, 30 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(display_frame, \"Initializing...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('ISS Live Feed with Computer Vision', display_frame)\n",
    "\n",
    "        # Press 'ESC' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # 27 is the ASCII code for ESC\n",
    "            break\n",
    "\n",
    "    # Write final message to the file\n",
    "    f.write(\"Analysis completed.\\n\")\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Analysis complete. Results written to iss_predictions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude TF, no training, online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jPTD2gnZFUw\n",
      "[youtube] jPTD2gnZFUw: Downloading webpage\n",
      "[youtube] jPTD2gnZFUw: Downloading ios player API JSON\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "[youtube] jPTD2gnZFUw: Downloading m3u8 information\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Analysis complete. Results written to C:/Users/dsrus/Desktop/Workspace/UAP_Python_2/iss_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yt_dlp\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set the working directory\n",
    "working_dir = 'C:/Users/dsrus/Desktop/Workspace/UAP_Python_2/'\n",
    "\n",
    "# Define the classes\n",
    "class_names = ['space', 'earth_broad', 'iss', 'panels']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = tf.keras.models.load_model(os.path.join(working_dir, 'fine_tuned_resnet50_tf.keras'))\n",
    "\n",
    "def predict(frame):\n",
    "    # Preprocess the frame\n",
    "    image = cv2.resize(frame, (224, 224))\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(image)\n",
    "    top_indices = predictions[0].argsort()[-4:][::-1]  # Get all 4 classes, sorted by probability\n",
    "    top_predictions = [(class_names[i], predictions[0][i]) for i in top_indices]\n",
    "    \n",
    "    return top_predictions\n",
    "\n",
    "# YouTube video URL\n",
    "url = \"https://www.youtube.com/watch?v=jPTD2gnZFUw\"\n",
    "\n",
    "# Use yt-dlp to get the stream URL\n",
    "ydl_opts = {'format': 'best'}\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info(url, download=False)\n",
    "    stream_url = info['url']\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "last_prediction_time = time.time()\n",
    "predictions = []\n",
    "\n",
    "# Open a file to write predictions\n",
    "predictions_file = os.path.join(working_dir, \"iss_predictions.txt\")\n",
    "with open(predictions_file, \"w\") as f:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize frame for display\n",
    "        display_frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "        # Make a prediction every 5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - last_prediction_time > 5:\n",
    "            predictions = predict(frame)\n",
    "            last_prediction_time = current_time\n",
    "            f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}: {', '.join([f'{p[0]} ({p[1]:.2f})' for p in predictions])}\\n\")\n",
    "            f.flush()  # Ensure the prediction is written to the file immediately\n",
    "\n",
    "        # Add predictions text to the frame\n",
    "        if predictions:\n",
    "            for i, (pred, prob) in enumerate(predictions):  # Display all 4 classes\n",
    "                cv2.putText(display_frame, f\"{i+1}. {pred} ({prob:.2f})\", (10, 30 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(display_frame, \"Initializing...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('ISS Live Feed with Computer Vision', display_frame)\n",
    "\n",
    "        # Press 'ESC' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # 27 is the ASCII code for ESC\n",
    "            break\n",
    "\n",
    "    # Write final message to the file\n",
    "    f.write(\"Analysis completed.\\n\")\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Analysis complete. Results written to {predictions_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude TF --- Download tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Analysis complete. Results written to C:/Users/dsrus/Desktop/Workspace/UAP_Python_2/iss_predictions_test.txt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set the working directory\n",
    "working_dir = 'C:/Users/dsrus/Desktop/Workspace/UAP_Python_2/'\n",
    "\n",
    "# Define the classes\n",
    "class_names = ['space', 'earth_broad', 'iss', 'panels']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = tf.keras.models.load_model(os.path.join(working_dir, 'fine_tuned_resnet50_tf.keras'))\n",
    "\n",
    "def predict(frame):\n",
    "    # Preprocess the frame\n",
    "    image = cv2.resize(frame, (224, 224))\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(image)\n",
    "    top_indices = predictions[0].argsort()[-4:][::-1]  # Get all 4 classes, sorted by probability\n",
    "    top_predictions = [(class_names[i], predictions[0][i]) for i in top_indices]\n",
    "    \n",
    "    return top_predictions\n",
    "\n",
    "# Path to the pre-downloaded video file\n",
    "video_path = 'C:/Users/dsrus/Desktop/Workspace/UAP_Python_2/sample_3/ISS_Download_1.mp4'\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count / fps\n",
    "\n",
    "last_prediction_time = 0\n",
    "predictions = []\n",
    "\n",
    "# Open a file to write predictions\n",
    "predictions_file = os.path.join(working_dir, \"iss_predictions_test.txt\")\n",
    "with open(predictions_file, \"w\") as f:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Get current timestamp in the video\n",
    "        current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "\n",
    "        # Resize frame for display\n",
    "        display_frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "        # Make a prediction every 5 seconds\n",
    "        if current_time - last_prediction_time >= 5:\n",
    "            predictions = predict(frame)\n",
    "            last_prediction_time = current_time\n",
    "            f.write(f\"Time: {current_time:.2f}s: {', '.join([f'{p[0]} ({p[1]:.2f})' for p in predictions])}\\n\")\n",
    "            f.flush()  # Ensure the prediction is written to the file immediately\n",
    "\n",
    "        # Add predictions text to the frame\n",
    "        if predictions:\n",
    "            for i, (pred, prob) in enumerate(predictions):  # Display all 4 classes\n",
    "                cv2.putText(display_frame, f\"{i+1}. {pred} ({prob:.2f})\", (10, 30 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(display_frame, \"Initializing...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('ISS Video Analysis', display_frame)\n",
    "\n",
    "        # Press 'ESC' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # 27 is the ASCII code for ESC\n",
    "            break\n",
    "\n",
    "    # Write final message to the file\n",
    "    f.write(\"Analysis completed.\\n\")\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Analysis complete. Results written to {predictions_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
